import torch
import torch.nn as nn
from torchvision import transforms, models
import cv2
import os
from pathlib import Path

BASE_DIR = Path(__file__).resolve().parent.parent.parent
model_path = os.path.join(BASE_DIR, 'skin_status', 'mobilenet_skin_best.pth')
num_classes = 6
device = torch.device("cpu")

# ğŸ” ëª¨ë¸ì„ ìµœì´ˆ 1íšŒë§Œ ë¡œë“œí•˜ë„ë¡ ì „ì—­ ë³€ìˆ˜ ì‚¬ìš©
_model = None

def get_model():
    global _model
    if _model is None:
        print(">>> ëª¨ë¸ ë¡œë”© ì¤‘...")
        m = models.mobilenet_v2(weights=None)
        m.classifier[1] = nn.Linear(m.classifier[1].in_features, num_classes)
        m.load_state_dict(torch.load(model_path, map_location=device))
        m = m.to(device)
        m.eval()
        _model = m
        print(">>> ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
    return _model

# âœ… ì „ì²˜ë¦¬
transform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.5]*3, [0.5]*3)
])

# âœ… ì¶”ë¡  í•¨ìˆ˜
def predict_acne_level(cv2_img):
    model = get_model()
    rgb_img = cv2.cvtColor(cv2_img, cv2.COLOR_BGR2RGB)
    input_tensor = transform(rgb_img).unsqueeze(0).to(device)
    with torch.no_grad():
        outputs = model(input_tensor)
        probs = torch.softmax(outputs, dim=1)
        pred = torch.argmax(probs, dim=1).item()
        confidence = probs[0][pred].item()
    return pred, confidence
